{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgEQCtp-A2Is"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/visiont3lab/tecnologie_data_science/blob/master/book/docs/pyspark/streaming_basic.ipynb\n",
    "\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kIvdUDuAynj"
   },
   "source": [
    "## PYSPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 432544,
     "status": "ok",
     "timestamp": 1592895800982,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "_4WMgsuL8Xki",
    "outputId": "de392aa2-6157-4514-8474-5babf829f8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosa vuoi monitorare ? salvini\n",
      "In attesa di una connessione TCP...\n",
      "Traceback (most recent call last):\n",
      "  File \"tweets_stream.py\", line 44, in <module>\n",
      "    conn, addr = s.accept()\n",
      "  File \"/usr/lib/python3.6/socket.py\", line 205, in accept\n",
      "    fd, addr = self._accept()\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python tweets_stream.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_LNmH1d_8QUq"
   },
   "source": [
    "# Introduzione a Spark Streaming\n",
    "Spark Streaming è un'estensione delle API di Spark che consente l'elaborazione di dati in streaming scalabile, ad alta velocità e resistente agli errori. Spark Streaming è in grado di prendere i dati da numerose fonti differenti : Kafka, Flume, Kinesis, S3, Socket TPC etc. I dati vengono elaborati in batch e inseriti all'interno di uno oggetto chiamato DStream.\n",
    "<br><br>\n",
    "In questo notebook introdurremo Spark Streaming in maniera pratica con alcuni esempi di base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZsGs4Ni8QUt"
   },
   "source": [
    "## Inizializziamo Spark\n",
    "Inizializziamo due contesti differenti, il contesto base di Spark (SparkContext) e il contesto per lo Streaming (StreamingContext). Per inizializzare lo StreamingContext dobbiamo usare due parametri, il primo è l'instanza della classe SparkContext ed il secondo è il tempo di campionamento di ogni batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LbGBN9ws8QUv"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "sc = SparkContext()\n",
    "ssc = StreamingContext(sc, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zw1Y3nFS8QU6"
   },
   "source": [
    "Fatto questo creiamo un DStream che conterrà i dati in streaming da una connessione TCP, specificando l'hostname e la porta.\n",
    "**NOTA BENE** Dato che lavoriamo in locale non dobbiamo proccuparci di un eventuale firewall, basta scegliere una porta che sia libera, solitamente le porte con un numero alto sono sempre libere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gcW2BKaq8QU9",
    "outputId": "ea34faef-afd6-437d-a8c5-93741b7d9de0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.streaming.dstream.DStream"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "type(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qHt641uZ8QVG"
   },
   "source": [
    "## Echo Streaming\n",
    "Come primo esempio non faremo altro che prendere il messaggio che viene trasmesso al DStream, dividerlo per parole e stamparlo su schermo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7mwMZBN8QVJ"
   },
   "outputs": [],
   "source": [
    "words = lines.flatMap(lambda text: text.split())\n",
    "words.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OJSIQWrW8QVT"
   },
   "source": [
    "Utilizziamo il programma nc da terminale per avviare un webserver e inviare dei messaggi via socket, è sufficente digitare il seguente comando da terminale:\n",
    "<br><br>\n",
    "**nc -lk 9999**\n",
    "<br><br>\n",
    "Ora avviamo lo StreamingContext usando il metodo *.start()* e lasciamolo in ascolto usando il metodo *.awaitTermination()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRtMondi8QVV",
    "outputId": "3df3e1b8-6c24-4ec9-9d20-0a519e19236e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2019-07-11 10:54:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-07-11 10:54:25\n",
      "-------------------------------------------\n",
      "ciao\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-07-11 10:54:30\n",
      "-------------------------------------------\n",
      "come\n",
      "stai\n",
      "?\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-07-11 10:54:35\n",
      "-------------------------------------------\n",
      "molto\n",
      "bene\n",
      "grazie\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-18f3db416f1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark/python/pyspark/streaming/context.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTerminationOrTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1286\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S15qezh-8QVh"
   },
   "source": [
    "posizionati sul terminale dove c'è nc in esecuzione ed invia dei messaggi, se hai fatto tutto correttamente le parole del tuo messaggio verranno stampate qui sopra. Appena abbiamo finito di giocare stoppiamo il contesto, altrimenti non potremmo proseguire con gli altri esempi, per sicurezza killiamo anche un'eventuale applicazione in ascolto sulla porta 9999.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4mXan-68QVk"
   },
   "outputs": [],
   "source": [
    "ssc.stop()\n",
    "!sudo kill $(sudo lsof -t -i:9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TU_Lhhvz8QVs"
   },
   "source": [
    "## Keywords monitoring\n",
    "Ora facciamo un'esempio lievemente più complesso, monitoriamo due keyword all'interno dei messaggi, verificando se sono presenti ed eventualmente contandone le occorrenze. Per poter proseguire dobbiamo reinizializzare il contesto e ricreare il DStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdH_7lYv8QVv"
   },
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "ssc = StreamingContext(sc, 5)\n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGQmLfO68QV5"
   },
   "source": [
    "Ora, sul nostro DStream, dividiamo i messaggi in base agli spazi, in modo da ottenere le parole, esattamente come fatto in precedenza, poi filtriamo solo i messaggi che contengono le keyword che stiamo monitorando, infine eseguiamo un map e reduceByKey per sommare il numero totale di volte che tale keyword è presente (se è presente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SItpOATg8QV7"
   },
   "outputs": [],
   "source": [
    "keywords = [\"sport\",\"calcio\"]\n",
    "\n",
    "lines.flatMap(lambda text: text.split()) \\\n",
    ".filter(lambda word: (word.lower() in keywords)) \\\n",
    ".map(lambda word: (word.lower(), 1)) \\\n",
    ".reduceByKey(lambda a,b: a+b) \\\n",
    ".pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81cgnW5L8QWD"
   },
   "source": [
    "Di nuovo da terminale avviamo nc (**nc -lk 9999**) poi avviamo lo StreamingContext e mettiamoci in ascolto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5LWs9nJO8QWF"
   },
   "outputs": [],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zdiqs2Dv8QWM"
   },
   "source": [
    "inviamo dei messaggi da nc, inserendo alcune volte le nostre keywords. Se hai fatto tutto correttamente, ogni volta che invii un messaggio contenente la keyword dovresti ottenere in output una tupla con la keyword e il numero di occorrenze. Fai attenzione che il numero di occorrenze è riferito soltanto al batch corrente, quindi non abbiamo una somma totale, ma soltato il numero di volte che le keyword sono presenti nell'ultimo batch di messaggi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DLXwPvBv8QWN"
   },
   "outputs": [],
   "source": [
    "ssc.stop()\n",
    "!sudo kill $(sudo lsof -t -i:9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Os4GhyZz8QWR"
   },
   "source": [
    "## Keyword counter\n",
    "Vediamo come possiamo bypassare il limite presente e contare il numero totale di volte che le keyword appaiono in tutti i messaggi che inviamo, in tempo reale. Reinizializziamo i contesti e in DStream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xM0bQqeV8QWS"
   },
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "ssc = StreamingContext(sc, 5)\n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftA0nenW8QWY"
   },
   "source": [
    "Definiamo una semplice funzione per aggregare i countatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6n-cHWMc8QWY"
   },
   "outputs": [],
   "source": [
    "def aggregate_count(new_values, total_sum):\n",
    "    add_1 = sum(new_values)\n",
    "    add_2 = (total_sum or 0) # se ci troiamo al primo batch total_sum sarà null, quindi torniamo 0\n",
    "    return add_1+add_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LIyFkAyI8QWc"
   },
   "source": [
    "Sostituiamo il metodo *.updateByKey(func)* con *.updateStateByKey(func)*, che ci permette di creare uno stato permanente tra i diversi batch, passiamo a questo metodo la funzione che abbiamo appena definito per eseguire la somma dei contatori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfIU-NJg8QWd"
   },
   "outputs": [],
   "source": [
    "lines.flatMap(lambda text: text.split()) \\\n",
    "    .filter(lambda word: (word.lower() in keywords)) \\\n",
    "    .map(lambda word: (word.lower(), 1)) \\\n",
    "    .updateStateByKey(aggregate_count) \\\n",
    "    .pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vYCjjFV8QWg"
   },
   "source": [
    "Per poter utilizzare uno stato dobbiamo creare una directory di checkpoint su disco, che permetterà a Spark di recuperare i dati in caso di errori, per farlo ci basta utilizzare il metodo *.checkpoint(path)* della classe StreamingContext, passando come parametro il path alla directory dove vogliamo creare il checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u3rBy_ni8QWh"
   },
   "outputs": [],
   "source": [
    "ssc.checkpoint(\"/home/ubuntu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zItcNx6C8QWk"
   },
   "source": [
    "Avviamo nc, poi avviamo lo StreamingContext e mettiamoci in ascolto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bMQ0W2eY8QWl"
   },
   "outputs": [],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5CQSlpdm8QWo"
   },
   "source": [
    "Fai qualche esperimento sempre usando nc, vedrai che ora il contatore è diventato permanente !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbEa_JI18QWo"
   },
   "outputs": [],
   "source": [
    "ssc.stop()\n",
    "!sudo kill $(sudo lsof -t -i:9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ARMLKVnE8QWu"
   },
   "source": [
    "## Registrare su una tabella SQL temporanea\n",
    "Certe volte può essere utili salvare i batch del DStream in una tabella SQL temporanea (cioè una view) per poi poter eseguire le nostre analisi. Vediamo come farlo. Creiamo ancora una volta i contesti e il DStream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3PNyKyXc8QWu"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "sc = SparkContext()\n",
    "ssc = StreamingContext(sc, 5)\n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sid_nyxa8QWx"
   },
   "source": [
    "Definiamo una funzione che ci permetterà di accedere globalmente al contesto SQL, questo è importante per poter inserire i dati di ogni batch dentro alla view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRyUh3Ve8QWx"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "def get_sql_context(spark_context):\n",
    "    if ('sqlContextSingletonInstance' not in globals()):\n",
    "        globals()['sqlContextSingletonInstance'] = SQLContext(spark_context)\n",
    "    return globals()['sqlContextSingletonInstance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kb81mig8QW0"
   },
   "source": [
    "Creiamo una funzione che prende in input un timestamp ed una RDD, l'RDD conterrà una parte del nostro DStream. Utilizziamo l'RDD per creare un Dataframe ed il Dataframe per creare una view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxxmxDKI8QW0"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "def process_rdd(time, rdd):\n",
    "    if(rdd.count()>0):\n",
    "        sql_context = get_sql_context(rdd.context)\n",
    "        row_rdd = rdd.map(lambda w: Row(name=w[0], count=w[1])) # usiamo l'RDD per creare una lista di righe\n",
    "        df = sql_context.createDataFrame(row_rdd) # Creiamo il Dataframe\n",
    "        df = df.createOrReplaceTempView(\"Popularity\") # Creiamo o aggiorniamo la View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tIjN4w-V8QW2"
   },
   "source": [
    "Ora piuttosto che stampare il DStream, utilizziamo il metodo *.foreachRDD(func)* per dividere il DStream in diversi RDD e passarli alla funzione che abbiamo definito sopra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UM5T8ec8QW2"
   },
   "outputs": [],
   "source": [
    "keywords = [\"calcio\",\"pallone\",\"rigori\",\"goal\",\"sport\"]\n",
    "\n",
    "lines.flatMap(lambda text: text.split()) \\\n",
    "  .filter(lambda word: (word.lower() in keywords)) \\\n",
    "  .map(lambda word: (word.lower(), 1)) \\\n",
    "  .updateStateByKey(aggregate_count) \\\n",
    "  .foreachRDD(process_rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_0KYgIME8QW4"
   },
   "source": [
    "Avviamo di nuovo nc, fatto questo, impostiamo il checkpoint e avviamo lo Streaming in maniera non bloccante, cioè senza chiamare il metodo *.awaitTermination()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmMSc78a8QW5"
   },
   "outputs": [],
   "source": [
    "ssc.checkpoint(\"/home/ubuntu\")\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPP6GPIl8QW7"
   },
   "source": [
    "Giochiamo un po' con nc da terminale per popolare la nostra tabella, quando siamo soddisfatti possiamo vederne il contenuto lanciando una query SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eX_mCXNb8QW-"
   },
   "source": [
    "Non dimenticarti che lo streaming sta continunado a girare in background, quindi quando hai finito terminalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sql_context(sc).sql(\"SELECT * FROM Popularity ORDER BY count DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fmj56U7S8QW_"
   },
   "outputs": [],
   "source": [
    "ssc.stop()\n",
    "!sudo kill $(sudo lsof -t -i:9999)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "streaming_basic.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
