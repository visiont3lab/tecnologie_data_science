{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4gYZhJQEFWmV"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/visiont3lab/tecnologie_data_science/blob/master/book/docs/pyspark/sentiment_analysis.ipynb\n",
    "\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ny8kdE7jCIWR"
   },
   "source": [
    "## PYSPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dllomvISCEs-"
   },
   "outputs": [],
   "source": [
    "################ template to run PySpark on Colab #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30825,
     "status": "ok",
     "timestamp": 1592863258374,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "5Yd_uDp4CMsm"
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
    "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30820,
     "status": "ok",
     "timestamp": 1592863258375,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "wggGRXj5CMpO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35564,
     "status": "ok",
     "timestamp": 1592863263123,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "gMtyjgiCCMnB"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark1 = SparkSession.builder.appName('basic').getOrCreate()\n",
    "#Test must give no error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35562,
     "status": "ok",
     "timestamp": 1592863263125,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "gbGnmRyXCMj8"
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35559,
     "status": "ok",
     "timestamp": 1592863263126,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "ZurQUHqzCVNh"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setAppName(\"basic\").setMaster(\"local\")\n",
    "#sc = SparkContext(conf=conf)  ## for jupyter and Databricks\n",
    "sc = SparkContext.getOrCreate()   ## for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35556,
     "status": "ok",
     "timestamp": 1592863263126,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "GVi3mLvhCVKN"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJ9yGBPxCVG7"
   },
   "outputs": [],
   "source": [
    "################ end template PySpark on Colab ##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SzxJDSJIIwuN"
   },
   "source": [
    "# Sentiment Analysis sulle Recensioni di Yelp\n",
    "La Sentiment Analysis è il processo di identificazione dell'emozione espressa in un testo, positiva o negativa.<br><br>\n",
    "In questo notebook useremo Spark e la sua MLlib per costruire un modello di Sentiment Analysis usando il dataset messo a disposizione da Yelp, una famossisima applicazione che permette di recensire locali e attività commerciali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 136739,
     "status": "ok",
     "timestamp": 1592863069238,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "UrcnUzeQB0w-",
    "outputId": "9918d883-0af1-46b5-b9d2-fb2c90f3252b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-22 21:55:33--  https://frenzy86.s3.eu-west-2.amazonaws.com/fav/bigdata/yelp_dataset.tgz\n",
      "Resolving frenzy86.s3.eu-west-2.amazonaws.com (frenzy86.s3.eu-west-2.amazonaws.com)... 52.95.149.50\n",
      "Connecting to frenzy86.s3.eu-west-2.amazonaws.com (frenzy86.s3.eu-west-2.amazonaws.com)|52.95.149.50|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4772313040 (4.4G) [application/octet-stream]\n",
      "Saving to: ‘yelp_dataset.tgz’\n",
      "\n",
      "yelp_dataset.tgz    100%[===================>]   4.44G  33.8MB/s    in 2m 15s  \n",
      "\n",
      "2020-06-22 21:57:48 (33.8 MB/s) - ‘yelp_dataset.tgz’ saved [4772313040/4772313040]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://frenzy86.s3.eu-west-2.amazonaws.com/fav/bigdata/yelp_dataset.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 295029,
     "status": "ok",
     "timestamp": 1592863227535,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "LdcifDH2IwuU"
   },
   "outputs": [],
   "source": [
    "!tar xf yelp_dataset.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kc6cyL7SIwuW"
   },
   "source": [
    "L'archivio contiene 4 file json differenti:\n",
    "* yelp_academic_dataset_business.json\n",
    "* yelp_academic_dataset_checkin.json\n",
    "* yelp_academic_dataset_review.json\n",
    "* yelp_academic_dataset_tip.json\n",
    "* yelp_academic_dataset_user.json\n",
    "\n",
    "Ognuno contiene delle informazioni differenti, quello con le recensioni è *yelp_academic_dataset_review.json* che è pesa oltre 5 GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DTl6FzxlIwuZ"
   },
   "source": [
    "## Importiamo il dataset in un DataFrame\n",
    "Importiamo il dataset in un DataFrame, trattandosi di un file json possiamo utilizzare la funzione .json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1592863380050,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "u6tQERMsDer8"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121656,
     "status": "ok",
     "timestamp": 1592863502377,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "YUENhrS6Iwua"
   },
   "outputs": [],
   "source": [
    "yelp_df = sqlContext.read.json('yelp_academic_dataset_review.json')\n",
    "#yelp_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X6tpOdcZIwuc"
   },
   "source": [
    "**ATTENZIONE**: Se dovessi ottenere un'errore di tipo *permission denied*, modifica i permessi sul file json e riprova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6kW2qwLyIwuc"
   },
   "outputs": [],
   "source": [
    "#!sudo chmod 777 yelp_academic_dataset_review.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyQCQh_HIwuf"
   },
   "source": [
    "Vediamo quali sono le colonne del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1592863514020,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "1lhHkaR8Iwuf",
    "outputId": "159cd19d-2636-41e1-9b91-0f4329d6dbcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business_id',\n",
       " 'cool',\n",
       " 'date',\n",
       " 'funny',\n",
       " 'review_id',\n",
       " 'stars',\n",
       " 'text',\n",
       " 'useful',\n",
       " 'user_id']"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lM5QRd12Iwui"
   },
   "source": [
    "Abbiamo ben 9 colonne, che sono:\n",
    "* user_id: identificativo del recensore\n",
    "* business_id: identificato del business recensito\n",
    "* review_id: identificativo della recensione\n",
    "* text: testo della recensione\n",
    "* date: data della recensione\n",
    "* stars: valutazione dell'attività (da 1.0 a 5.0).\n",
    "* useful: numero di utenti che hanno segnato la recensione come uile\n",
    "* cool: numero degli utenti che hanno segnato la recensione come toga (si dice ancora toga? Forse no).\n",
    "* funny: numero di utenti che hanno segnato la recensione come divertente.\n",
    "\n",
    "Le uniche informazioni che a noi interessano sono il testo e la valutazione, creiamo un nuovo DataFrame con soltanto queste colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1592863518049,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "VznwH1RvIwuj"
   },
   "outputs": [],
   "source": [
    "reviews_df = yelp_df.select([\"text\", \"stars\"])\n",
    "#reviews_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8R4zdllSIwul"
   },
   "source": [
    "Quante recensioni abbiamo a disposizione ? Non lo so, contiamole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117643,
     "status": "ok",
     "timestamp": 1592863637362,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "ahAVn554Iwum",
    "outputId": "fb41f8b1-456f-466e-b499-b1eb61322faf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8021122"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ytoxdcOuIwuo"
   },
   "source": [
    "Le recensioni sono ben 8.021.122, davvero tante ! Facciamo una cosa, cominciamo creando un modello utilizzando soltanto il 1% del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117393,
     "status": "ok",
     "timestamp": 1592863754770,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "csU8JHG1Iwup",
    "outputId": "37e5af94-f5a1-498a-86d3-7ce5e1f91a06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80458"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreviews_df = reviews_df.sample(False, 0.01, seed=0)\n",
    "subreviews_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAcObZkIIwut"
   },
   "source": [
    "## Preprocessing del testo\n",
    "Ora dobbiamo processare il testo delle recensioni per renderlo un buon input per una modello di machine learning. Iniziamo rimuovendo tutta la punteggiatura da ogni frase. Definiamo una funzione per farlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117381,
     "status": "ok",
     "timestamp": 1592863754773,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "ypc3127lIwuu",
    "outputId": "3a2f54fd-09c3-442a-8343-bc05fad64132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'che cacchio dici 1'"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def remove_punct(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "remove_punct(\"...che cacchio dici !!!1!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAhM1OL6Iwuw"
   },
   "source": [
    "Utilizziamo la funzione *udf* (User Defined Function - Funzione Definita dall'Utente) per creare una funzione spark partendo da quella che abbiamo definito noi per la rimozione della punteggiatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 112548,
     "status": "ok",
     "timestamp": 1592863754774,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "0Q5mBor8Iwux"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "punct_remove = udf(lambda s: remove_punct(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCmkswmRIwuz"
   },
   "source": [
    "Fatto questo applichiamo la funzione alla colonna text, per rimuovere la punteggiatura da ogni recensione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 109912,
     "status": "ok",
     "timestamp": 1592863754775,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "3_Pa51WYIwu0"
   },
   "outputs": [],
   "source": [
    "subreviews_df = subreviews_df.withColumn(\"text\", punct_remove(reviews_df[\"text\"]))\n",
    "#reviews_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6zEyLy2Iwu3"
   },
   "source": [
    "Fantastico ! Prossimo step, eseguire la **Tokenizzazione**, che ci serve per estrarre i **Token** dal testo, cioè le sue parti costituenti (le parole insomma). Per farlo possiamo usare la classe *Tokenizer* di MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 103432,
     "status": "ok",
     "timestamp": 1592863755029,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "3YTZS8kzIwu4"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "words_df = tokenizer.transform(subreviews_df)\n",
    "\n",
    "#words_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-Veyez1Iwu5"
   },
   "source": [
    "Ora abbiamo ogni recensione rappresentata da una lista di parole, molte di queste parole sono superflue e non portano informazioni utili ai fini della sentiment analysis. Tali parole sono dette StopWords ed è buona pratica rimuoverle, possiamo farlo utilizzando la classe *StopWordsRemover* di MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 98137,
     "status": "ok",
     "timestamp": 1592863755270,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "dglzAiaMIwu6"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "stopwords = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "words_df = stopwords.transform(words_df)\n",
    "\n",
    "#words_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYvTjj_0Iwu8"
   },
   "source": [
    "Adesso abbiamo ogni recensione rappresentata da una lista di parole utili, ma un modello di Machine Learning non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 217778,
     "status": "ok",
     "timestamp": 1592863878364,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "4AT0j4TYIwu8"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(inputCol='filtered', outputCol='features')\n",
    "cv_model = cv.fit(words_df)\n",
    "cv_df = cv_model.transform(words_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4dWTH6D9Iwu_"
   },
   "source": [
    "Ora scartiamo pure tutte le colonne intermedie che abbiamo creato tenendo soltanto quelle che ci serviranno per realizzare il modello, features e stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 214674,
     "status": "ok",
     "timestamp": 1592863878367,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "Fssc-z8EIwvB"
   },
   "outputs": [],
   "source": [
    "cv_df = cv_df.select([\"features\",\"stars\"])\n",
    "#data_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfdNsBV7IwvF"
   },
   "source": [
    "## Quali sono le recensioni negative ?\n",
    "Come abbiamo già detto le recensioni sono accompagnate da una valutazione che va da 1.0 a 5.0 stelle, etichettiamo come positive le recensioni con una valutazione di almeno 3.5 stelle, mentre come negative quelle con una valutazione inferiore alle 2.5 stelle. <br>\n",
    "Le recensioni con 3 stelle sono tendenzialmente neutre, quindi rimuoviamole dal dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 212205,
     "status": "ok",
     "timestamp": 1592863879026,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "cPno9-jmIwvG"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "cv_df = cv_df.filter(\"stars != 3.0\")\n",
    "cv_df = cv_df.withColumn(\"label\", when(cv_df[\"stars\"]>=3.5, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QxIx5gkhIwvI"
   },
   "source": [
    "Utilizziamo il metodo *randomSplit* per dividere il DataFrame in due:\n",
    "* un DataFrame per l'addestramento del modello che conterrà il 70% degli esempi.\n",
    "* un DataFrame per il testing del modello che conterrà il restante 30% degli esempi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1592865101328,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "Hm7dZweZIwvJ"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = cv_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hL3jEpA2IwvL"
   },
   "source": [
    "Ora possiamo creare il modello, utilizziamo una Regressione Logistica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 199628,
     "status": "ok",
     "timestamp": 1592865302589,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "qSUax_VfIwvM"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZw0DHApIwvN"
   },
   "source": [
    "Valutiamo il modello addestrato sul DataFrame di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 549183,
     "status": "ok",
     "timestamp": 1592865655056,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "jZWPmYBIIwvO",
    "outputId": "efa3e97f-e329-4204-a593-0beab2297a2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9103168005911149\n",
      "[0.8340807174887892, 0.9381937436932392]\n",
      "[0.8314993122420908, 0.9392600075767142]\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(test_df)\n",
    "print(evaluation.accuracy)\n",
    "print(evaluation.precisionByLabel)\n",
    "print(evaluation.recallByLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMK1SzunIwvQ"
   },
   "source": [
    "## Creiamo un modello con tutti i dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-Uo2WzEIwvQ"
   },
   "source": [
    "Bene, adesso addestriamo il modello utilizzando il dataset per intero con tutti le sue 8.021.122 recensioni.\n",
    "<br><br>\n",
    "**ATTENZIONE** Il processo di creazione del modello richiede molte risorse di calcolo e, di conseguenza, tempo. Dovresti utilizzare almeno una macchina EC2 di tipo t3a.large (costo ~7 centesimi l'ora) o meglio ancora un cluster con EMR.\n",
    "<br><br>\n",
    "Rimuoviamo la punteggiatura dal testo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1592863879653,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "zUekk1J-IwvR"
   },
   "outputs": [],
   "source": [
    "data_df = reviews_df.withColumn(\"text\", punct_remove(reviews_df[\"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVRv1mtJIwvS"
   },
   "source": [
    "Eseguiamo la tokenizzazione e rimuoviamo le stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1592863879654,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "OKI8yhxFIwvT"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "data_df = tokenizer.transform(data_df)\n",
    "\n",
    "stopwords = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "data_df = stopwords.transform(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqWVtS7bIwvV"
   },
   "source": [
    "Questa volta, piuttosto che usare un semplice modello Bag of Words per la rappresentazione delle parole, usiamo un modello più sofisticato, cioè il **TF-IDF** (Term Frequency - Inverse Document Frequency) che assegna un peso maggiore alle parole più rare e penalizza quelle più comuni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1174526,
     "status": "ok",
     "timestamp": 1592865053575,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "qYukextOIwvW"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "hashing_tf = HashingTF(inputCol='filtered', outputCol='raw_features')\n",
    "data_df = hashing_tf.transform(data_df)\n",
    "\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idf_model = idf.fit(data_df)\n",
    "data_df = idf_model.transform(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsDlIxfNIwvX"
   },
   "source": [
    "Creiamo la colonna per il target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1174524,
     "status": "ok",
     "timestamp": 1592865053577,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "A5aoCcc0IwvY"
   },
   "outputs": [],
   "source": [
    "data_df = data_df.filter(\"stars != 3.0\")\n",
    "data_df = data_df.withColumn(\"label\", when(data_df[\"stars\"]>=3.5, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwvohznWIwvZ"
   },
   "source": [
    "Dividiamo il dataframe in set di addestramento e di test, avendo moltissimi esempi possiamo anche ridurre la dimensione del set di test all'10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1174522,
     "status": "ok",
     "timestamp": 1592865053578,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "RT_jLcN5IwvZ"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = data_df.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddvvWMl3Iwvb"
   },
   "source": [
    "Creiamo il modello e addestriamolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 729380,
     "status": "ok",
     "timestamp": 1592865847515,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "wmkEye3-Iwvb"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d0YTlVKwIwvd"
   },
   "source": [
    "Valutiamolo sul set di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1078167,
     "status": "ok",
     "timestamp": 1592866200526,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "oUko_MfkIwvd",
    "outputId": "ec1c1b6f-4105-4911-f1ed-b1fac8addd54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9103168005911149\n",
      "[0.8340807174887892, 0.9381937436932392]\n",
      "[0.8314993122420908, 0.9392600075767142]\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(test_df)\n",
    "print(evaluation.accuracy)\n",
    "print(evaluation.precisionByLabel)\n",
    "print(evaluation.recallByLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pfeKosQbIwvg"
   },
   "source": [
    "## Testiamo il Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1587,
     "status": "ok",
     "timestamp": 1592866202130,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "8L5SFlksIwvh"
   },
   "outputs": [],
   "source": [
    "reviews = [\n",
    "        (\"World's Largest Entertainment McDonald's\",\"Lazy staff who do not want to serve u would rather stand in corners in groups talking stood at counter 10 minutes with all staff refusing eye contact as fear of having to serve u supervisor went over and shouted at staff they all stood there shrugging shoulders not wanting t serve u then when orders were ready staff came with trays dragging feet and rolling eyes then it was cold horrible won’t return !!\"),\n",
    "        (\"Disnayland Paris\",\"Went here 2x with my husband and found it more magical the 2nd time. Still the happiest place on earth on my list. It gets better and better.\"),\n",
    "        (\"58 Tour Eiffel Restaurant\",\"What an experience! what a VIEW!. what a meal!!... Delicious, fine dining. excellent0 excellent service and food. A memory of a lifetime\"),\n",
    "        (\"Ristorante Cracco\",\"If you want to start your trip in Milan with good mood, for sure you have to avoid this restaurant - the worst pizza we had and the smallest portion of pasta! And incompatible price for that everything! Even, I am really angry, because this is not my first visit in Italy and not first pizza and I feel myself like ....!!!!\"),\n",
    "        (\"Happy Wok\",\"Stay away as far as you can, unless you like goopy tables and mass produced food that appeared to be sitting out for too long. It wasn’t a nice experience and we will not attempt to go back under any circumstance\"),\n",
    "        (\"Pepe in grani\",\"45 minutes driving from Naples center. Worth every moment on the way. The best and the most unique pizza I ever tasted. Very nice place, every centimeter was well though and planned before implemented. Nice terrace on top for those like the view. Very welcoming crew, great and fast service. Recommend to order the tasting option for those coming in parties of four. \")\n",
    "    ]\n",
    "\n",
    "test_df = sqlContext.createDataFrame(reviews, [\"location\",\"text\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1572,
     "status": "ok",
     "timestamp": 1592866202131,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "ROIlF3jEIwvj"
   },
   "outputs": [],
   "source": [
    "test_df = test_df.withColumn(\"text\", punct_remove(test_df[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1563,
     "status": "ok",
     "timestamp": 1592866202132,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "DYbjh14DIwvm"
   },
   "outputs": [],
   "source": [
    "test_df = tokenizer.transform(test_df)\n",
    "test_df = stopwords.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1553,
     "status": "ok",
     "timestamp": 1592866202133,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "fgHh2YU7Iwvo"
   },
   "outputs": [],
   "source": [
    "test_df = hashing_tf.transform(test_df)\n",
    "test_df = idf_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1543,
     "status": "ok",
     "timestamp": 1592866202134,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "r7D8xO7WIwvq"
   },
   "outputs": [],
   "source": [
    "pred_df = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwQfwHJFIwvt"
   },
   "outputs": [],
   "source": [
    "#pred_df = pred_df.select([\"text\", \"label\"])\n",
    "pred_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2322,
     "status": "aborted",
     "timestamp": 1592866202928,
     "user": {
      "displayName": "T3Lab Vision",
      "photoUrl": "",
      "userId": "14779383426442114373"
     },
     "user_tz": -120
    },
    "id": "zJWT9IUgIwvu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sentiment_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
